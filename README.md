# Visual Perception

My personal experiments with perception algorithms. (more content comming soon).

More appealing esthetics: [![link](https://img.shields.io/badge/docs-cool%20stuff!-blue.svg)](https://ssaket.github.io/visual-perception/)

## Introduction

Visual Perception in simple terms is the ability to perceive our surroundings through the light which enters our eyes. It enables us to experience what is out there in the environment.

## Model of Perceptual Processing

### Three-stage model [Colin Ware, 2000]

- **Stage 1:**

    Extract low-level features, basically extraction of features, orientation, color, texture, and movement patterns

- **Stage 2:**

    Find patterns, motion and segment the visual scene into regions of different color, textures

- **Stage 3:**

    Active sequential scanning/searching, the information is reduced and stored to form basic of visual thinking.

## Gestalt Laws

- Law of Proximity
- Law of Similarity
- Law of Connectedness
- Law of Continuity
- Law of Closure
- Law of Good Form
- Law of Common Fate

## Blog

### Deep learning architectures

- [Inception Architecture](blogs/inception.md)

- [Common CNN Architectures](blogs/common_cnns.md)

## Deep learning Models

1. [`CIFAR_AuBN.ipynb`](models/CIFAR_AuBN.ipynb) : CIFAR with Data Augumentation and Batch Normalization.
2. [`CIFAR-basic.ipynb`](models/CIFAR-basic.ipynb): Plain old CIFAR
3. [`fashionMNIST.ipynb`](models/fashionMNIST.ipynb): Plain CNN network for classification task.
4. [`lenet-mnist.ipynb`](models/lenet-mnist.ipynb): LeNet architecture in pytorch
5. [`VGG16.ipynb`](models/VGG16.ipynb): Feature selection and gain some insights